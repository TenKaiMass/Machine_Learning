{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "binPN-FDOmt4"
   },
   "source": [
    "# Modèle linéaire\n",
    "\n",
    "Considérons la cas classique d'une fonction affine :\n",
    "\n",
    "$$y=ax+b$$\n",
    "\n",
    "Ici, $a$ et $b$ sont des réels. Ces deux nombres définissent entièrement la courbe et permet donc d'obtenir une relation **affine** entre $x$ et $y$. En statistique, cette relation est à la base des modèles dit **linéaires**, où une variable réponse se définit comme une somme de variables explicatives où chacune de ces dernières sont multipliés par un coefficient.\n",
    "\n",
    "\n",
    "## Modèle linéaire simple\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/438px-Linear_regression.svg.png)\n",
    "\n",
    "Dans le modèle linéaire simple (une seule variable explicative), on suppose que la variable réponse suit le modèle suivant :\n",
    "\n",
    "$$y_i=\\beta_0 + \\beta_1 x_i + \\varepsilon_i$$\n",
    "\n",
    "On remarque la ressemblance avec la fonction affine présentée ci-dessus. La différence réside dans l'existence du terme aléatoire (appelé bruit) $\\varepsilon_i$. Afin de considérer le modèle, il est nécessaire de se placer sous les hypothèses suivantes\n",
    "\n",
    "$$(\\mathcal{H}) : \\left\\{\\begin{matrix}\n",
    "\\mathbb{E}[\\varepsilon_i]=0\\\\ \n",
    "\\text{Cov}(\\varepsilon_i, \\varepsilon_j)=\\delta_{ij} \\sigma^2\n",
    "\\end{matrix}\\right.$$\n",
    "Les différents éléments qui interviennent sont :\n",
    "\n",
    "- $\\beta_0$ : l'ordonnée à l'origine (nommée *intercept*)\n",
    "- $\\beta_1$ : le coefficient directeur\n",
    "- $x_i$ : l'observation $i$\n",
    "- $y_i$ : le $i$-ème prix\n",
    "- $\\varepsilon_i$ : le bruit aléatoire liée à la $i$-ème observation\n",
    "\n",
    "La solution peut se calculer facilement via les formules fermées suivantes :\n",
    "\n",
    "$$\\hat{\\beta}_1=\\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2} \\qquad \\hat{\\beta}_0 = \\hat{y} - \\hat{\\beta}_1 \\bar{x}$$\n",
    "\n",
    "## Modèle linéaire multiple\n",
    "\n",
    "Dans le cas multiple (pour $p$ variables explicatives), pour la $i$-ème observation, le modèle s'écrit :\n",
    "\n",
    "$$y_i= \\beta_0 + \\sum_{j=1}^p \\beta_j x_{ij} + \\varepsilon_i$$\n",
    "\n",
    "Ainsi, une observation $x_i$ n'est plus une valeur, mais un **vecteur** $(x_{i1}, \\dots, x_{ip})$. Il est plus commode de regrouper ces prix $y_i$ et ces vecteurs d'observations $x_i$ dans des matrices :\n",
    "\n",
    "$$Y=X \\beta + \\varepsilon$$\n",
    "\n",
    "Sous les hypothèses équivalentes du modèle simple en plus grand dimension\n",
    "\n",
    "$$(\\mathcal{H}) : \\left\\{\\begin{matrix}\n",
    "\\text{rank}(X)=p\\\\ \n",
    "\\mathbb{E}[\\varepsilon]=0 \\text{ et }\\text{Var}(\\varepsilon)=\\sigma^2 I_p\n",
    "\\end{matrix}\\right.$$\n",
    "\n",
    "Les différents éléments qui interviennent sont :\n",
    "\n",
    "- $\\beta$ : le vecteur directeur\n",
    "- $X$ : la matrice des observations\n",
    "- $Y$ : le vecteur de prix\n",
    "- $\\varepsilon$ : le vecteur de bruit\n",
    "\n",
    "Avec $X=( \\mathbf{1}, X_1, \\dots, X_n)$, $Y=(y_1, \\dots, y_n)^\\top$ et $\\varepsilon=(\\varepsilon_1, \\dots, \\varepsilon_n)^\\top$. La solution des MCO (Moindres Carrés Ordinaires) est alors :\n",
    "\n",
    "$$\\hat{\\beta}= (X^\\top X)^{-1} X^\\top Y$$\n",
    "\n",
    "Vous pouvez d'ailleurs faire la démonstration de votre coté ! Pour plus d'information mathématiques, le portail de wikipédia qui est très bien fait : [lien ici](https://fr.wikipedia.org/wiki/Portail:Probabilit%C3%A9s_et_statistiques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRQO2ydTOmuA"
   },
   "source": [
    "# Implémenter une régression linéaire \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ckyBi2FLOmuE"
   },
   "outputs": [],
   "source": [
    "#importer vos librairies \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6I-a12SOmud",
    "outputId": "cbe1bdef-5dda-429a-a4f9-81fc4df45794"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>person_capacity</th>\n",
       "      <th>beds</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>is_rebookable</th>\n",
       "      <th>is_new_listing</th>\n",
       "      <th>is_fully_refundable</th>\n",
       "      <th>is_host_highly_rated</th>\n",
       "      <th>is_business_travel_ready</th>\n",
       "      <th>pricing_weekly_factor</th>\n",
       "      <th>pricing_monthly_factor</th>\n",
       "      <th>available</th>\n",
       "      <th>local_price</th>\n",
       "      <th>min_nights</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56093</th>\n",
       "      <td>12.0</td>\n",
       "      <td>48.867284</td>\n",
       "      <td>2.358431</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57207</th>\n",
       "      <td>13.0</td>\n",
       "      <td>48.846184</td>\n",
       "      <td>2.304455</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.48294</td>\n",
       "      <td>49.952756</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114543</th>\n",
       "      <td>19.0</td>\n",
       "      <td>48.849530</td>\n",
       "      <td>2.290219</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.14026</td>\n",
       "      <td>107.374026</td>\n",
       "      <td>3.716883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0   latitude  longitude  person_capacity  beds  bedrooms  \\\n",
       "listing_id                                                                      \n",
       "56093             12.0  48.867284   2.358431              4.0   2.0       1.0   \n",
       "57207             13.0  48.846184   2.304455              2.0   1.0       1.0   \n",
       "114543            19.0  48.849530   2.290219              2.0   1.0       1.0   \n",
       "\n",
       "            bathrooms  is_rebookable  is_new_listing  is_fully_refundable  \\\n",
       "listing_id                                                                  \n",
       "56093             1.0            0.0             0.0                  1.0   \n",
       "57207             1.0            0.0             0.0                  1.0   \n",
       "114543            1.0            0.0             0.0                  1.0   \n",
       "\n",
       "            is_host_highly_rated  is_business_travel_ready  \\\n",
       "listing_id                                                   \n",
       "56093                        1.0                       0.0   \n",
       "57207                        0.0                       0.0   \n",
       "114543                       1.0                       0.0   \n",
       "\n",
       "            pricing_weekly_factor  pricing_monthly_factor  available  \\\n",
       "listing_id                                                             \n",
       "56093                        0.88                     1.0    0.00000   \n",
       "57207                        0.87                     1.0    0.48294   \n",
       "114543                       0.90                     0.9    0.14026   \n",
       "\n",
       "            local_price  min_nights  \n",
       "listing_id                           \n",
       "56093        170.000000    4.000000  \n",
       "57207         49.952756    2.000000  \n",
       "114543       107.374026    3.716883  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#charger les données \n",
    "data_price = pd.read_csv(\"./dataset/price_availability.csv\",sep=\";\")\n",
    "data_listing = pd.read_csv(\"./dataset/listings_final.csv\",sep=\";\")\n",
    "#price_availability.csv\n",
    "#listings_final.csv\n",
    "#vérifier si tous les individus ont bien un prix\n",
    "data_fusion = pd.merge(data_listing,data_price, on=\"listing_id\")\n",
    "data_final = data_fusion.groupby('listing_id').mean()\n",
    "data_final.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XT3LsnvVOmut"
   },
   "source": [
    "## Données d'entrée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8DTTFEKOmu0"
   },
   "source": [
    "L'objectif ici est de charger les données pour créer les matrices $X$ et $Y$ du modèle linéaire. **Attention**, il n'est pas nécessaire de rajouter le vecteur colonne $\\mathbf{1}$ en première colonne, car *scikit-learn* le fait automatiquement !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnTd7XKdOmu5"
   },
   "outputs": [],
   "source": [
    "#fusion des dataset\n",
    "\n",
    "\n",
    "#définir 2 variables de travail\n",
    "#X := les features à utiliser \n",
    "X = data_final.drop('local_price',axis=1)\n",
    "#Y := la target (prix)\n",
    "Y = data_final['local_price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_zalIbpOmvI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.519716661465031"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#construire l'ensemble de donnée prix \n",
    "#\n",
    "#    INDICE \n",
    "# \n",
    "# récupérer les prix des ID dans le dataset de prix \n",
    "# 🚧 il y a plusieurs prix dans le dataset 🚧\n",
    "model = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z1ckoHuzOmvW"
   },
   "source": [
    "En *Machine Learning*, on a l'habitude de couper l'ensemble de données en deux sous-ensembles :\n",
    "\n",
    "- Un ensemble d'entraînement (*train set*), sur lequel le modèle va être calibré.\n",
    "- Un ensemble de test (*test set*), qui ne sera pas utilisé pendant le calibrage mais permettra de vérifier l'aptitude du modèle à généraliser sur de nouvelles observations inconnues.\n",
    "\n",
    "En général, on découpe l'ensemble de données (*split*) en prenant $\\alpha \\%$ de l'ensemble pour entraînement et $1-\\alpha \\%$ comme test. Dans la plus part des cas, on considère que $\\alpha=10,20 ou 30\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-x-APn4OmvX",
    "outputId": "ff55319f-f6d2-477c-811e-f1eb2d5ef7b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape X : {}, shape Y : {} (999, 16) (999,)\n"
     ]
    }
   ],
   "source": [
    "#utiliser la méthode split de sklearn en splitant avec un alpha=30 et un random state=42 \n",
    "#afficher la shape de vos données \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,random_state=42,)\n",
    "print(\"shape X : {}, shape Y : {}\", format(X.shape),format(Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szd_JPzXOmvq"
   },
   "source": [
    "## Entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1e4cfWxoOmvr"
   },
   "source": [
    "Pour information, *scikit-learn* utilise le solveur OLS (Ordinary Least Squares) de *numpy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TrS4fboZOmvu",
    "outputId": "9a26f504-379b-45b3-b498-8b37befc4e30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#créer l'objet de régression et entrainer le sur notre ensemble d'entraînement\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "40mJxNwhOmv5"
   },
   "source": [
    "On affiche le vecteur des coefficients pour interpréter rapidement le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUjLZYBEOmv7",
    "outputId": "3ac3800a-e028-46d6-e367-f64e1232d3bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5070533354309714"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#afficher les coefficients\n",
    "model.score(X_train,Y_train)\n",
    "#que remarquez vous ? \n",
    "#il a environ  1 chance sur 2 de predir le bon prix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nt4z_sh4OmwI"
   },
   "source": [
    "## Validation du modèle\n",
    "\n",
    "### Le coefficient de détermination $R^2$\n",
    "\n",
    "Par la suite, nous ferons l'hypothèse de gaussianité sur les bruits. Dans l'idée, nous aimerions obtenir une valeur numérique qui nous indique à quel point la régression linéaire a un sens sur nos données. Pour cela, introduisons les notations suivantes :\n",
    "\n",
    "- $SCT=\\|Y-\\hat{y} \\mathbf{1}\\|^2$ est la somme des carrés totaux\n",
    "- $SCE=\\|\\hat{Y}-\\hat{y} \\mathbf{1}\\|^2$ est la somme des carrés expliqués\n",
    "- $SCR=\\|\\hat{\\varepsilon}\\|^2$ est la somme des carrés résiduels\n",
    "\n",
    "L'idée est de décomposer la somme des carrés totaux comme la somme des carrés que le modèle explique, en plus de la somme des carrés qui sont liés aux résidus (et donc que le modèle ne peut pas expliquer). On voit donc ici l'intérêt de calculer un coefficient à partir du $SCE$. Puisque l'on a la relation suivante :\n",
    "\n",
    "$$SCT=SCE+SCR \\text{ alors } 1=\\frac{SCE}{SCT}+\\frac{SCR}{SCT}$$\n",
    "\n",
    "Plus les résidus sont petits (et donc la régression est \"bonne\"), plus $SCR$ devient petit et donc $SCE$ devient grand. Le schéma inverse s'opère de la même façon. Dans le meilleur des cas, on obtient $SCR=0$ et donc $SCE=SCT$ d'où le premier membre vaut $1$. Dans le cas contraite, $SCE=0$ et automatiquement, le premier membre est nul. C'est ainsi que l'on définit le coefficient de détermination $R^2$ comme \n",
    "$$R^2=\\frac{SCE}{SCT}=1-\\frac{SCR}{SCT}$$\n",
    "Ainsi, $R^2 \\in [0,1]$. Plus $R^2$ est proche de $1$, plus la régression linéaire a du sens. Au contraire, si $R^2$ est proche de $0$, le modèle linéaire possède un faible pouvoir explicatif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uf8_Sw5yOmwJ",
    "outputId": "5035a388-7cdb-4346-f833-d47fdabf2bc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  64.52856224,  639.37106141,  130.1949791 ,  117.46358751,\n",
       "         66.66224071,  545.11780521,   26.86270012, -251.27875606,\n",
       "        170.27429863,  445.1345808 ,  131.94568163,  134.63214893,\n",
       "        330.1278098 ,  254.14321307,  219.7634768 ,  229.18400556,\n",
       "        258.90645769,  114.93338906,  239.43173168,  240.98800709,\n",
       "        102.51791333,   60.2168461 ,  500.58888903,  182.42777747,\n",
       "        104.60716937,  399.3391158 ,  200.78890661,  160.82011775,\n",
       "        226.29699206,   74.88830081,  145.16325589,  170.24508473,\n",
       "        157.12559984,  176.48416832,   17.82168241,  245.10145054,\n",
       "         16.41347411,  400.52579917,  251.48307205,  138.3847261 ,\n",
       "        206.90060499,   26.9961518 ,  232.7922148 ,  305.74733174,\n",
       "         73.88862685,   96.02790816,  280.53912082,  178.13820636,\n",
       "         81.27134555,   94.56638905,  277.07529025,   86.73029733,\n",
       "        242.16564764,  257.44483937,  200.5903852 ,  272.59016994,\n",
       "        160.92329954,   46.92739708,  482.69814829,  495.03924358,\n",
       "        178.0309277 ,  179.50693939,  329.81055208,   35.72130106,\n",
       "        433.80901453,  202.02846147,   89.39626878,  122.1551078 ,\n",
       "        170.04605506,  274.97955758,   68.09132301,  392.55158308,\n",
       "        302.16237761,  305.58770882,  138.60681374,   39.89648762,\n",
       "        335.1748038 ,  104.87723503,  203.36597032,  187.69327452,\n",
       "         48.07056071,  307.18029453,  131.94311903,  426.48805227,\n",
       "        394.78284976,  242.40089976,  289.96530067,   75.96322935,\n",
       "        135.39031681,  389.19882996,  279.36373163,  184.66973016,\n",
       "        266.50473658,   13.11691032,  139.10667713,  141.25154571,\n",
       "        252.45827892,  221.13546414,   71.09468004,  155.42039712,\n",
       "        252.59107724,  222.88285911,   41.81246396,  217.8935644 ,\n",
       "        363.13593005,   46.93189129,  261.4587419 ,  169.8705023 ,\n",
       "        242.73624235,   24.92504996,  274.90517434,  193.66118021,\n",
       "        129.06039126,   78.32255226,   46.41103824,  307.3535273 ,\n",
       "        126.85524404,  136.5870142 ,  277.76163819,  264.77516028,\n",
       "        500.52811588,  107.74400673,   98.70751289,   75.67592287,\n",
       "        -11.94716076,  166.18373575,   15.43161977,  277.14084814,\n",
       "        181.01036124,   52.62290216,   10.81084029,  345.41560932,\n",
       "        256.93711671,  111.12845365,   98.76237792,  252.69765828,\n",
       "        120.63116829,  363.4856303 ,  101.47397211,  243.38017604,\n",
       "         95.33899981,  196.69114252,  589.08810001,  389.96903422,\n",
       "        251.71019723,  169.52296785,  638.6485945 ,  329.14721285,\n",
       "        278.28959816,   64.34290747,  149.42898681,  244.08815408,\n",
       "        180.59986945,   61.9628146 ,  126.67554928,  661.59407578,\n",
       "        121.7394539 ,   51.63813064,  228.84441934,    8.37163687,\n",
       "        253.1128067 ,   83.5872237 ,   88.14787777,  242.68180566,\n",
       "        157.95889982,  148.931609  ,   12.20557212,  357.70508586,\n",
       "         90.36936007,  110.59825363,   41.17733059,  204.49216308,\n",
       "        291.56901207,    2.48871318,  218.60364582,  407.48754239,\n",
       "        353.87715611,   24.85140033,  371.36355625,  537.24541008,\n",
       "        134.09633128,   78.55438487,  117.58572725,  112.97792683,\n",
       "        388.05920806,  149.62301866,  304.78295929,  238.03937424,\n",
       "         88.34660923,  290.76102256,  308.4783436 ,  209.94698606,\n",
       "        182.92843538,  482.81887322,  310.22256285,   97.1365611 ,\n",
       "         96.27594521,  401.95010265,  233.14579092,   46.98647644,\n",
       "        488.54773227,  221.36116226,   74.83949216,   58.03675127,\n",
       "         11.82877919,  346.25769762,  245.1566893 ,   89.16318214,\n",
       "         91.24543632,  136.30266385,  101.30081945,  325.90700215,\n",
       "        234.34371301,  166.17426919,   50.34636503,   99.70425994,\n",
       "        195.40631757,  264.3268371 ,  242.72391135,   99.852914  ,\n",
       "        312.08102089,   50.29750264,   27.46453204,  171.02617881,\n",
       "        219.77349282,  369.93368876,  197.93914972,  196.01880424,\n",
       "         52.34121589,  199.34258793,  209.15449162,  123.95284438,\n",
       "        231.04295494,  142.94603296,   -2.86089645,  110.48757111,\n",
       "        202.74315351,  179.51952606,  437.98426911,  163.85545665,\n",
       "         81.41646257,  165.02123678,   57.70703476,   53.18616341,\n",
       "        208.86224137,   64.01732113,  118.10272878,   29.46136684,\n",
       "         49.94236993,  445.19848902])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#faire une prediction sur X\n",
    "prediction = model.predict(X_test)\n",
    "prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEQrrOb6OmwV",
    "outputId": "f5e692a4-e10f-4a15-d37a-a12edfc7aaaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.54542305789064"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#afficher l'erreur des moindres carrées sur l'ensemble d'entrainement ainsi que le R2\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "errors = mean_absolute_error(Y_test, prediction)\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3C3r6tz9Omwd"
   },
   "source": [
    "## Bonus : Analyse de l'homoscédasticité\n",
    "\n",
    "L'analyse de l'homoscédasticité est primordiale : c'est en particulier elle qui nous permet de vérifier, à partir des résidus, si les bruits vérifient bien l'hypothèse $(\\mathcal{H})$. On calcule donc les **résidus studentisés**.\n",
    "\n",
    "$$t_i^*=\\frac{\\hat{\\varepsilon}_i}{\\hat{\\sigma}_{(i)} \\sqrt{1-h_{ii}}}$$\n",
    "Avec $h_{ii}=\\{X(X^\\top X)^{-1} X^\\top\\}_{ii}=H_{ii}$ la matrice de projection sur l'hyperplan des variables. Plus précisément, $H$ est la matrice qui projette $Y$ sur l'espace engendré par les variables, soit $\\hat{Y}=HY$. De même, on considère $\\hat{\\sigma}_{(i)}$ l'estimateur de la variance du bruit en supprimant l'observation $i$ (par une méthode de validation croisée Leave-One-Out que nous ne détaillerons pas ici).\n",
    "\n",
    "Dans ce cas, on peut montrer que les résidus studentisés suivent une loi de Student à $n-p-1$ degrés de liberté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QC71Z7HhOmwf",
    "outputId": "ab8657d8-81d0-4c77-871a-d232178a2537"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4964/2206579234.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#analyser le code ci-dessous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'regr' is not defined"
     ]
    }
   ],
   "source": [
    "#analyser le code ci-dessous \n",
    "import scipy\n",
    "Y_pred = regr.predict(X_train)\n",
    "n = X_train.shape[0]\n",
    "p = 4\n",
    "residuals = np.abs(y_train - Y_pred)\n",
    "H = np.matmul(X_train, np.linalg.solve(np.dot(X_train.T, X_train), X_train.T))\n",
    "std_hat = np.dot(residuals, residuals) / (n - p)\n",
    "standart_residuals = np.asarray([residuals[i] / np.sqrt(std_hat * (1 - H[i, i])) for i in range(len(residuals))])\n",
    "student_residuals = np.asarray([ standart_residuals[i] * np.sqrt((n - p - 1) / (n - p - standart_residuals[i]**2)) for i in range(n) ])\n",
    "cook = np.asarray([ H[i, i] * student_residuals[i] / (X_train.shape[1] * (1 - H[i, i])) for i in range(n) ])\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.subplot(221)\n",
    "plt.scatter(Y_pred, student_residuals, s=12, c=\"white\", edgecolors=\"blue\")\n",
    "plt.plot([min(Y_pred), max(Y_pred)], [ scipy.stats.t.ppf(q=0.975, df=n-p-1), scipy.stats.t.ppf(q=0.975, df=n-p-1)], color=\"green\", alpha=0.6, label=\"Quantile de Student\")\n",
    "plt.title(\"Analyse de l’homoscédasticité\")\n",
    "plt.xlabel(\"Prédictions $\\hat{y}_i$\")\n",
    "plt.ylabel(\"Résidus studentisés $|t_i^*|$\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHy-a9jROmws"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ModeleLineaire1.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
