{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "binPN-FDOmt4"
   },
   "source": [
    "# Mod√®le lin√©aire\n",
    "\n",
    "Consid√©rons la cas classique d'une fonction affine :\n",
    "\n",
    "$$y=ax+b$$\n",
    "\n",
    "Ici, $a$ et $b$ sont des r√©els. Ces deux nombres d√©finissent enti√®rement la courbe et permet donc d'obtenir une relation **affine** entre $x$ et $y$. En statistique, cette relation est √† la base des mod√®les dit **lin√©aires**, o√π une variable r√©ponse se d√©finit comme une somme de variables explicatives o√π chacune de ces derni√®res sont multipli√©s par un coefficient.\n",
    "\n",
    "\n",
    "## Mod√®le lin√©aire simple\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/438px-Linear_regression.svg.png)\n",
    "\n",
    "Dans le mod√®le lin√©aire simple (une seule variable explicative), on suppose que la variable r√©ponse suit le mod√®le suivant :\n",
    "\n",
    "$$y_i=\\beta_0 + \\beta_1 x_i + \\varepsilon_i$$\n",
    "\n",
    "On remarque la ressemblance avec la fonction affine pr√©sent√©e ci-dessus. La diff√©rence r√©side dans l'existence du terme al√©atoire (appel√© bruit) $\\varepsilon_i$. Afin de consid√©rer le mod√®le, il est n√©cessaire de se placer sous les hypoth√®ses suivantes\n",
    "\n",
    "$$(\\mathcal{H}) : \\left\\{\\begin{matrix}\n",
    "\\mathbb{E}[\\varepsilon_i]=0\\\\ \n",
    "\\text{Cov}(\\varepsilon_i, \\varepsilon_j)=\\delta_{ij} \\sigma^2\n",
    "\\end{matrix}\\right.$$\n",
    "Les diff√©rents √©l√©ments qui interviennent sont :\n",
    "\n",
    "- $\\beta_0$ : l'ordonn√©e √† l'origine (nomm√©e *intercept*)\n",
    "- $\\beta_1$ : le coefficient directeur\n",
    "- $x_i$ : l'observation $i$\n",
    "- $y_i$ : le $i$-√®me prix\n",
    "- $\\varepsilon_i$ : le bruit al√©atoire li√©e √† la $i$-√®me observation\n",
    "\n",
    "La solution peut se calculer facilement via les formules ferm√©es suivantes :\n",
    "\n",
    "$$\\hat{\\beta}_1=\\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2} \\qquad \\hat{\\beta}_0 = \\hat{y} - \\hat{\\beta}_1 \\bar{x}$$\n",
    "\n",
    "##¬†Mod√®le lin√©aire multiple\n",
    "\n",
    "Dans le cas multiple (pour $p$ variables explicatives), pour la $i$-√®me observation, le mod√®le s'√©crit :\n",
    "\n",
    "$$y_i= \\beta_0 + \\sum_{j=1}^p \\beta_j x_{ij} + \\varepsilon_i$$\n",
    "\n",
    "Ainsi, une observation $x_i$ n'est plus une valeur, mais un **vecteur** $(x_{i1}, \\dots, x_{ip})$. Il est plus commode de regrouper ces prix $y_i$ et ces vecteurs d'observations $x_i$ dans des matrices :\n",
    "\n",
    "$$Y=X \\beta + \\varepsilon$$\n",
    "\n",
    "Sous les hypoth√®ses √©quivalentes du mod√®le simple en plus grand dimension\n",
    "\n",
    "$$(\\mathcal{H}) : \\left\\{\\begin{matrix}\n",
    "\\text{rank}(X)=p\\\\ \n",
    "\\mathbb{E}[\\varepsilon]=0 \\text{ et }\\text{Var}(\\varepsilon)=\\sigma^2 I_p\n",
    "\\end{matrix}\\right.$$\n",
    "\n",
    "Les diff√©rents √©l√©ments qui interviennent sont :\n",
    "\n",
    "- $\\beta$ : le vecteur directeur\n",
    "- $X$ : la matrice des observations\n",
    "- $Y$ : le vecteur de prix\n",
    "- $\\varepsilon$ : le vecteur de bruit\n",
    "\n",
    "Avec $X=( \\mathbf{1}, X_1, \\dots, X_n)$, $Y=(y_1, \\dots, y_n)^\\top$ et $\\varepsilon=(\\varepsilon_1, \\dots, \\varepsilon_n)^\\top$. La solution des MCO (Moindres Carr√©s Ordinaires) est alors :\n",
    "\n",
    "$$\\hat{\\beta}= (X^\\top X)^{-1} X^\\top Y$$\n",
    "\n",
    "Vous pouvez d'ailleurs faire la d√©monstration de votre cot√© ! Pour plus d'information math√©matiques, le portail de wikip√©dia qui est tr√®s bien fait : [lien ici](https://fr.wikipedia.org/wiki/Portail:Probabilit%C3%A9s_et_statistiques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRQO2ydTOmuA"
   },
   "source": [
    "# Impl√©menter une r√©gression lin√©aire \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ckyBi2FLOmuE"
   },
   "outputs": [],
   "source": [
    "#importer vos librairies \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6I-a12SOmud",
    "outputId": "cbe1bdef-5dda-429a-a4f9-81fc4df45794"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>person_capacity</th>\n",
       "      <th>beds</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>is_rebookable</th>\n",
       "      <th>is_new_listing</th>\n",
       "      <th>is_fully_refundable</th>\n",
       "      <th>is_host_highly_rated</th>\n",
       "      <th>is_business_travel_ready</th>\n",
       "      <th>pricing_weekly_factor</th>\n",
       "      <th>pricing_monthly_factor</th>\n",
       "      <th>available</th>\n",
       "      <th>local_price</th>\n",
       "      <th>min_nights</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56093</th>\n",
       "      <td>12.0</td>\n",
       "      <td>48.867284</td>\n",
       "      <td>2.358431</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57207</th>\n",
       "      <td>13.0</td>\n",
       "      <td>48.846184</td>\n",
       "      <td>2.304455</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.48294</td>\n",
       "      <td>49.952756</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114543</th>\n",
       "      <td>19.0</td>\n",
       "      <td>48.849530</td>\n",
       "      <td>2.290219</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.14026</td>\n",
       "      <td>107.374026</td>\n",
       "      <td>3.716883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0   latitude  longitude  person_capacity  beds  bedrooms  \\\n",
       "listing_id                                                                      \n",
       "56093             12.0  48.867284   2.358431              4.0   2.0       1.0   \n",
       "57207             13.0  48.846184   2.304455              2.0   1.0       1.0   \n",
       "114543            19.0  48.849530   2.290219              2.0   1.0       1.0   \n",
       "\n",
       "            bathrooms  is_rebookable  is_new_listing  is_fully_refundable  \\\n",
       "listing_id                                                                  \n",
       "56093             1.0            0.0             0.0                  1.0   \n",
       "57207             1.0            0.0             0.0                  1.0   \n",
       "114543            1.0            0.0             0.0                  1.0   \n",
       "\n",
       "            is_host_highly_rated  is_business_travel_ready  \\\n",
       "listing_id                                                   \n",
       "56093                        1.0                       0.0   \n",
       "57207                        0.0                       0.0   \n",
       "114543                       1.0                       0.0   \n",
       "\n",
       "            pricing_weekly_factor  pricing_monthly_factor  available  \\\n",
       "listing_id                                                             \n",
       "56093                        0.88                     1.0    0.00000   \n",
       "57207                        0.87                     1.0    0.48294   \n",
       "114543                       0.90                     0.9    0.14026   \n",
       "\n",
       "            local_price  min_nights  \n",
       "listing_id                           \n",
       "56093        170.000000    4.000000  \n",
       "57207         49.952756    2.000000  \n",
       "114543       107.374026    3.716883  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#charger les donn√©es \n",
    "data_price = pd.read_csv(\"./dataset/price_availability.csv\",sep=\";\")\n",
    "data_listing = pd.read_csv(\"./dataset/listings_final.csv\",sep=\";\")\n",
    "#price_availability.csv\n",
    "#listings_final.csv\n",
    "#v√©rifier si tous les individus ont bien un prix\n",
    "data_fusion = pd.merge(data_listing,data_price, on=\"listing_id\")\n",
    "data_final = data_fusion.groupby('listing_id').mean()\n",
    "data_final.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XT3LsnvVOmut"
   },
   "source": [
    "## Donn√©es d'entr√©e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8DTTFEKOmu0"
   },
   "source": [
    "L'objectif ici est de charger les donn√©es pour cr√©er les matrices $X$ et $Y$ du mod√®le lin√©aire. **Attention**, il n'est pas n√©cessaire de rajouter le vecteur colonne $\\mathbf{1}$ en premi√®re colonne, car *scikit-learn* le fait automatiquement !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnTd7XKdOmu5"
   },
   "outputs": [],
   "source": [
    "#fusion des dataset\n",
    "\n",
    "\n",
    "#d√©finir 2 variables de travail\n",
    "#X := les features √† utiliser \n",
    "X = data_final.drop('local_price',axis=1)\n",
    "#Y := la target (prix)\n",
    "Y = data_final['local_price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_zalIbpOmvI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.519716661465031"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#construire l'ensemble de donn√©e prix \n",
    "#\n",
    "#    INDICE \n",
    "# \n",
    "# r√©cup√©rer les prix des ID dans le dataset de prix \n",
    "# üöß il y a plusieurs prix dans le dataset üöß\n",
    "model = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z1ckoHuzOmvW"
   },
   "source": [
    "En *Machine Learning*, on a l'habitude de couper l'ensemble de donn√©es en deux sous-ensembles :\n",
    "\n",
    "- Un ensemble d'entra√Ænement (*train set*), sur lequel le mod√®le va √™tre calibr√©.\n",
    "- Un ensemble de test (*test set*), qui ne sera pas utilis√© pendant le calibrage mais permettra de v√©rifier l'aptitude du mod√®le √† g√©n√©raliser sur de nouvelles observations inconnues.\n",
    "\n",
    "En g√©n√©ral, on d√©coupe l'ensemble de donn√©es (*split*) en prenant $\\alpha \\%$ de l'ensemble pour entra√Ænement et $1-\\alpha \\%$ comme test. Dans la plus part des cas, on consid√®re que $\\alpha=10,20 ou 30\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-x-APn4OmvX",
    "outputId": "ff55319f-f6d2-477c-811e-f1eb2d5ef7b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape X : {}, shape Y : {} (999, 16) (999,)\n"
     ]
    }
   ],
   "source": [
    "#utiliser la m√©thode split de sklearn en splitant avec un alpha=30 et un random state=42 \n",
    "#afficher la shape de vos donn√©es \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,random_state=42,)\n",
    "print(\"shape X : {}, shape Y : {}\", format(X.shape),format(Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szd_JPzXOmvq"
   },
   "source": [
    "## Entra√Ænement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1e4cfWxoOmvr"
   },
   "source": [
    "Pour information, *scikit-learn* utilise le solveur OLS (Ordinary Least Squares) de *numpy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TrS4fboZOmvu",
    "outputId": "9a26f504-379b-45b3-b498-8b37befc4e30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cr√©er l'objet de r√©gression et entrainer le sur notre ensemble d'entra√Ænement\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "40mJxNwhOmv5"
   },
   "source": [
    "On affiche le vecteur des coefficients pour interpr√©ter rapidement le mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUjLZYBEOmv7",
    "outputId": "3ac3800a-e028-46d6-e367-f64e1232d3bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5070533354309714"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#afficher les coefficients\n",
    "model.score(X_train,Y_train)\n",
    "#que remarquez vous ? \n",
    "#il a environ  1 chance sur 2 de predir le bon prix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nt4z_sh4OmwI"
   },
   "source": [
    "## Validation du mod√®le\n",
    "\n",
    "### Le coefficient de d√©termination $R^2$\n",
    "\n",
    "Par la suite, nous ferons l'hypoth√®se de gaussianit√© sur les bruits. Dans l'id√©e, nous aimerions obtenir une valeur num√©rique qui nous indique √† quel point la r√©gression lin√©aire a un sens sur nos donn√©es. Pour cela, introduisons les notations suivantes :\n",
    "\n",
    "- $SCT=\\|Y-\\hat{y} \\mathbf{1}\\|^2$ est la somme des carr√©s totaux\n",
    "- $SCE=\\|\\hat{Y}-\\hat{y} \\mathbf{1}\\|^2$ est la somme des carr√©s expliqu√©s\n",
    "- $SCR=\\|\\hat{\\varepsilon}\\|^2$ est la somme des carr√©s r√©siduels\n",
    "\n",
    "L'id√©e est de d√©composer la somme des carr√©s totaux comme la somme des carr√©s que le mod√®le explique, en plus de la somme des carr√©s qui sont li√©s aux r√©sidus (et donc que le mod√®le ne peut pas expliquer). On voit donc ici l'int√©r√™t de calculer un coefficient √† partir du $SCE$. Puisque l'on a la relation suivante :\n",
    "\n",
    "$$SCT=SCE+SCR \\text{ alors } 1=\\frac{SCE}{SCT}+\\frac{SCR}{SCT}$$\n",
    "\n",
    "Plus les r√©sidus sont petits (et donc la r√©gression est \"bonne\"), plus $SCR$ devient petit et donc $SCE$ devient grand. Le sch√©ma inverse s'op√®re de la m√™me fa√ßon. Dans le meilleur des cas, on obtient $SCR=0$ et donc $SCE=SCT$ d'o√π le premier membre vaut $1$. Dans le cas contraite, $SCE=0$ et automatiquement, le premier membre est nul. C'est ainsi que l'on d√©finit le coefficient de d√©termination $R^2$ comme \n",
    "$$R^2=\\frac{SCE}{SCT}=1-\\frac{SCR}{SCT}$$\n",
    "Ainsi, $R^2 \\in [0,1]$. Plus $R^2$ est proche de $1$, plus la r√©gression lin√©aire a du sens. Au contraire, si $R^2$ est proche de $0$, le mod√®le lin√©aire poss√®de un faible pouvoir explicatif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uf8_Sw5yOmwJ",
    "outputId": "5035a388-7cdb-4346-f833-d47fdabf2bc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  64.52856224,  639.37106141,  130.1949791 ,  117.46358751,\n",
       "         66.66224071,  545.11780521,   26.86270012, -251.27875606,\n",
       "        170.27429863,  445.1345808 ,  131.94568163,  134.63214893,\n",
       "        330.1278098 ,  254.14321307,  219.7634768 ,  229.18400556,\n",
       "        258.90645769,  114.93338906,  239.43173168,  240.98800709,\n",
       "        102.51791333,   60.2168461 ,  500.58888903,  182.42777747,\n",
       "        104.60716937,  399.3391158 ,  200.78890661,  160.82011775,\n",
       "        226.29699206,   74.88830081,  145.16325589,  170.24508473,\n",
       "        157.12559984,  176.48416832,   17.82168241,  245.10145054,\n",
       "         16.41347411,  400.52579917,  251.48307205,  138.3847261 ,\n",
       "        206.90060499,   26.9961518 ,  232.7922148 ,  305.74733174,\n",
       "         73.88862685,   96.02790816,  280.53912082,  178.13820636,\n",
       "         81.27134555,   94.56638905,  277.07529025,   86.73029733,\n",
       "        242.16564764,  257.44483937,  200.5903852 ,  272.59016994,\n",
       "        160.92329954,   46.92739708,  482.69814829,  495.03924358,\n",
       "        178.0309277 ,  179.50693939,  329.81055208,   35.72130106,\n",
       "        433.80901453,  202.02846147,   89.39626878,  122.1551078 ,\n",
       "        170.04605506,  274.97955758,   68.09132301,  392.55158308,\n",
       "        302.16237761,  305.58770882,  138.60681374,   39.89648762,\n",
       "        335.1748038 ,  104.87723503,  203.36597032,  187.69327452,\n",
       "         48.07056071,  307.18029453,  131.94311903,  426.48805227,\n",
       "        394.78284976,  242.40089976,  289.96530067,   75.96322935,\n",
       "        135.39031681,  389.19882996,  279.36373163,  184.66973016,\n",
       "        266.50473658,   13.11691032,  139.10667713,  141.25154571,\n",
       "        252.45827892,  221.13546414,   71.09468004,  155.42039712,\n",
       "        252.59107724,  222.88285911,   41.81246396,  217.8935644 ,\n",
       "        363.13593005,   46.93189129,  261.4587419 ,  169.8705023 ,\n",
       "        242.73624235,   24.92504996,  274.90517434,  193.66118021,\n",
       "        129.06039126,   78.32255226,   46.41103824,  307.3535273 ,\n",
       "        126.85524404,  136.5870142 ,  277.76163819,  264.77516028,\n",
       "        500.52811588,  107.74400673,   98.70751289,   75.67592287,\n",
       "        -11.94716076,  166.18373575,   15.43161977,  277.14084814,\n",
       "        181.01036124,   52.62290216,   10.81084029,  345.41560932,\n",
       "        256.93711671,  111.12845365,   98.76237792,  252.69765828,\n",
       "        120.63116829,  363.4856303 ,  101.47397211,  243.38017604,\n",
       "         95.33899981,  196.69114252,  589.08810001,  389.96903422,\n",
       "        251.71019723,  169.52296785,  638.6485945 ,  329.14721285,\n",
       "        278.28959816,   64.34290747,  149.42898681,  244.08815408,\n",
       "        180.59986945,   61.9628146 ,  126.67554928,  661.59407578,\n",
       "        121.7394539 ,   51.63813064,  228.84441934,    8.37163687,\n",
       "        253.1128067 ,   83.5872237 ,   88.14787777,  242.68180566,\n",
       "        157.95889982,  148.931609  ,   12.20557212,  357.70508586,\n",
       "         90.36936007,  110.59825363,   41.17733059,  204.49216308,\n",
       "        291.56901207,    2.48871318,  218.60364582,  407.48754239,\n",
       "        353.87715611,   24.85140033,  371.36355625,  537.24541008,\n",
       "        134.09633128,   78.55438487,  117.58572725,  112.97792683,\n",
       "        388.05920806,  149.62301866,  304.78295929,  238.03937424,\n",
       "         88.34660923,  290.76102256,  308.4783436 ,  209.94698606,\n",
       "        182.92843538,  482.81887322,  310.22256285,   97.1365611 ,\n",
       "         96.27594521,  401.95010265,  233.14579092,   46.98647644,\n",
       "        488.54773227,  221.36116226,   74.83949216,   58.03675127,\n",
       "         11.82877919,  346.25769762,  245.1566893 ,   89.16318214,\n",
       "         91.24543632,  136.30266385,  101.30081945,  325.90700215,\n",
       "        234.34371301,  166.17426919,   50.34636503,   99.70425994,\n",
       "        195.40631757,  264.3268371 ,  242.72391135,   99.852914  ,\n",
       "        312.08102089,   50.29750264,   27.46453204,  171.02617881,\n",
       "        219.77349282,  369.93368876,  197.93914972,  196.01880424,\n",
       "         52.34121589,  199.34258793,  209.15449162,  123.95284438,\n",
       "        231.04295494,  142.94603296,   -2.86089645,  110.48757111,\n",
       "        202.74315351,  179.51952606,  437.98426911,  163.85545665,\n",
       "         81.41646257,  165.02123678,   57.70703476,   53.18616341,\n",
       "        208.86224137,   64.01732113,  118.10272878,   29.46136684,\n",
       "         49.94236993,  445.19848902])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#faire une prediction sur X\n",
    "prediction = model.predict(X_test)\n",
    "prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEQrrOb6OmwV",
    "outputId": "f5e692a4-e10f-4a15-d37a-a12edfc7aaaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.54542305789064"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#afficher l'erreur des moindres carr√©es sur l'ensemble d'entrainement ainsi que le R2\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "errors = mean_absolute_error(Y_test, prediction)\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3C3r6tz9Omwd"
   },
   "source": [
    "## Bonus : Analyse de l'homosc√©dasticit√©\n",
    "\n",
    "L'analyse de l'homosc√©dasticit√© est primordiale : c'est en particulier elle qui nous permet de v√©rifier, √† partir des r√©sidus, si les bruits v√©rifient bien l'hypoth√®se $(\\mathcal{H})$. On calcule donc les **r√©sidus studentis√©s**.\n",
    "\n",
    "$$t_i^*=\\frac{\\hat{\\varepsilon}_i}{\\hat{\\sigma}_{(i)} \\sqrt{1-h_{ii}}}$$\n",
    "Avec $h_{ii}=\\{X(X^\\top X)^{-1} X^\\top\\}_{ii}=H_{ii}$ la matrice de projection sur l'hyperplan des variables. Plus pr√©cis√©ment, $H$ est la matrice qui projette $Y$ sur l'espace engendr√© par les variables, soit $\\hat{Y}=HY$. De m√™me, on consid√®re $\\hat{\\sigma}_{(i)}$ l'estimateur de la variance du bruit en supprimant l'observation $i$ (par une m√©thode de validation crois√©e Leave-One-Out que nous ne d√©taillerons pas ici).\n",
    "\n",
    "Dans ce cas, on peut montrer que les r√©sidus studentis√©s suivent une loi de Student √† $n-p-1$ degr√©s de libert√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QC71Z7HhOmwf",
    "outputId": "ab8657d8-81d0-4c77-871a-d232178a2537"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4964/2206579234.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#analyser le code ci-dessous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'regr' is not defined"
     ]
    }
   ],
   "source": [
    "#analyser le code ci-dessous \n",
    "import scipy\n",
    "Y_pred = regr.predict(X_train)\n",
    "n = X_train.shape[0]\n",
    "p = 4\n",
    "residuals = np.abs(y_train - Y_pred)\n",
    "H = np.matmul(X_train, np.linalg.solve(np.dot(X_train.T, X_train), X_train.T))\n",
    "std_hat = np.dot(residuals, residuals) / (n - p)\n",
    "standart_residuals = np.asarray([residuals[i] / np.sqrt(std_hat * (1 - H[i, i])) for i in range(len(residuals))])\n",
    "student_residuals = np.asarray([ standart_residuals[i] * np.sqrt((n - p - 1) / (n - p - standart_residuals[i]**2)) for i in range(n) ])\n",
    "cook = np.asarray([ H[i, i] * student_residuals[i] / (X_train.shape[1] * (1 - H[i, i])) for i in range(n) ])\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.subplot(221)\n",
    "plt.scatter(Y_pred, student_residuals, s=12, c=\"white\", edgecolors=\"blue\")\n",
    "plt.plot([min(Y_pred), max(Y_pred)], [ scipy.stats.t.ppf(q=0.975, df=n-p-1), scipy.stats.t.ppf(q=0.975, df=n-p-1)], color=\"green\", alpha=0.6, label=\"Quantile de Student\")\n",
    "plt.title(\"Analyse de l‚Äôhomosc√©dasticit√©\")\n",
    "plt.xlabel(\"Pr√©dictions $\\hat{y}_i$\")\n",
    "plt.ylabel(\"R√©sidus studentis√©s $|t_i^*|$\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHy-a9jROmws"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ModeleLineaire1.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
